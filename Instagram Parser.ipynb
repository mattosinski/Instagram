{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/18130499/how-to-scrape-instagram-with-beautifulsoup\n",
    "#for maco sx, download chrome driver - https://sites.google.com/a/chromium.org/chromedriver/downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCSV (file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#URL = 'https://www.instagram.com/explore/tags/chapelhill/?hl=en' #hoboken location\n",
    "\n",
    "def instaURL (URL):\n",
    "    driver = webdriver.Chrome('/Users/Matt/Downloads/chromedriver')  # Optional argument, if not specified will search path.\n",
    "    driver.get(URL);\n",
    "    time.sleep(1) # Let the user actually see something!\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Click on \"Load more...\" label\n",
    "    load_more = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/article/div[2]/div[3]/a')\n",
    "    load_more.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    time.sleep(5) # Let the user actually see something!\n",
    "    driver.quit()\n",
    "    \n",
    "    #isolate the owner IDs from the pictures\n",
    "    stringTest=\"\"\n",
    "    for x in soup:\n",
    "        stringTest = stringTest + str(x)\n",
    "        #print x\n",
    "    pic_pattern='''(?<=\"owner\").*?(?=\"owner\")'''\n",
    "    pic = re.findall(pic_pattern, stringTest)\n",
    "    output = pic\n",
    "    #print output\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def formatHashtag(hashtag):\n",
    "    \n",
    "    outputTag=\"\"\n",
    "    hashtagDict = []\n",
    "    #print hashtag\n",
    "    listRange = range(len(hashtag))\n",
    "    for i in listRange:\n",
    "        iterator = i\n",
    "        for x in hashtag[(i+1):]:\n",
    "            outputTag+=hashtag[i]+ \",\" + (x) + \"\\n\"\n",
    "    #print outputTag\n",
    "    return outputTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(Source, City):\n",
    "    hashtagout=\"\"\n",
    "    df = pd.DataFrame()\n",
    "    CityFileName = str('InstaOutputMain_'+City+'.csv')\n",
    "    CityFileListName = str('InstaOutputlist_'+City+'.csv')\n",
    "    ofile  = open(CityFileName, \"wb\")\n",
    "    ofile.write(\"date\" + \",\" + \"pictureURL\" +\",\"+ \"numLikes\" +\",\"+ \"City\" + \",\" + \"hashtagout\" + \"\\n\")\n",
    "    #ofile_list  = open(CityFileListName, \"wb\") create\n",
    "    ofile_list  = open(CityFileListName, \"a+\") #append\n",
    "    ofile_list.write(\"tag1\" + \",\" + \"tag2\"+ \"\\n\")\n",
    "    for test in Source:  \n",
    "        ownerID_pattern='''(?<=: {\"id\": \").*?(?=\"},)'''\n",
    "        ownerID = re.search(ownerID_pattern, test)\n",
    "        ownerID = ownerID.group(0)\n",
    "        #print ownerID\n",
    "\n",
    "        video_pattern='''(?<=\"is_video\": ).*?(?=,)'''\n",
    "        video = re.search(video_pattern, test)\n",
    "        if video: video = video.group(0)\n",
    "        else: video=\"N/A\"\n",
    "\n",
    "        pictureURL_pattern='''(?<=\"display_src\": \").*?(?=\"},)'''\n",
    "        pictureURL = re.search(pictureURL_pattern, test)\n",
    "        if pictureURL: pictureURL = pictureURL.group(0)\n",
    "        else: pictureURL=\"N/A\"\n",
    "\n",
    "        date_pattern='''(?<=\"date\": ).*?(?=,)'''\n",
    "        date = re.search(date_pattern, test)\n",
    "        date = date.group(0)\n",
    "        date = datetime.datetime.fromtimestamp(int(date)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        commentsCount_pattern='''(?<=\"comments\": {\"count\": ).*?(?=},)'''\n",
    "        commentsCount = re.search(commentsCount_pattern, test)\n",
    "        numComments = commentsCount.group(0)\n",
    "\n",
    "        numLikes=\"N/A\"\n",
    "        likesCount_pattern='''(?<=\"likes\": {\"count\": ).*?(?=},)'''\n",
    "        likesCount = re.search(likesCount_pattern, test)\n",
    "        numLikes = likesCount.group(0)\n",
    "\n",
    "        caption_pattern='''(?<=\"caption\": \").*?(?=, \"likes\":)'''\n",
    "        caption = re.search(caption_pattern, test)\n",
    "        hashtagtext=\"N/A\"\n",
    "        if caption:\n",
    "            hashtagtext = caption.group(0)\n",
    "\n",
    "        hashtag = \"N/A\"\n",
    "        hashtag_pattern='''(?<=#).*?(?=\\W)'''\n",
    "        hashtag = re.findall(hashtag_pattern, hashtagtext)\n",
    "\n",
    "        \n",
    "        #print hashtag\n",
    "        df = df.append({ 'ownerID': ownerID,\n",
    "                           'isVideo': video,\n",
    "                           'pictureURL': pictureURL,\n",
    "                           'date': date,\n",
    "                           'numComments': numComments,\n",
    "                           'numLikes': numLikes,\n",
    "                           'caption': hashtagtext,\n",
    "                        'hashtag': hashtag\n",
    "            }, ignore_index=True)\n",
    "        #additional data cleanup\n",
    "        cols = df.columns.tolist()\n",
    "        cols = ['caption',\n",
    "         'date',\n",
    "         'isVideo',\n",
    "         'numComments',\n",
    "         'numLikes', 'pictureURL', 'ownerID','hashtag']\n",
    "        df=df[cols]\n",
    "\n",
    "        #print hashtag\n",
    "        \n",
    "        \n",
    "        formatHashtag(hashtag)\n",
    "        ofile_list.write(formatHashtag(hashtag))\n",
    "\n",
    "        hashtagout=\"\"\n",
    "        for x in hashtag:\n",
    "            hashtagout += x + \"\\t\"\n",
    "            \n",
    "        \n",
    "        ofile.write(date + \"\\t\" + pictureURL +\"\\t\"+ numLikes +\"\\t\"+ City + \"\\t\" + hashtagout + \"\\n\")\n",
    "\n",
    "    return \"Check InstaOutput.txt file for output\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCities(df):\n",
    "    for index, row in df.iterrows():\n",
    "        URL= row['Link']\n",
    "        City = row['City']\n",
    "        output=instaURL(URL)\n",
    "        parse(output,City)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matt/anaconda2/anaconda/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "file = '/Users/Matt/Documents/Stevens/BIA 658 Social Network Analytics/Instagram/Data/Cities List.csv'\n",
    "df = readCSV(file)\n",
    "#df['Link'][1]\n",
    "getCities(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#output=instaURL(URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
